{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/BijoSebastian/grasp_it_repo/blob/main/grasp_planning_vanilla_architectures.ipynb",
      "authorship_tag": "ABX9TyO1ql+X1J2Xyy56LeqEVLsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BijoSebastian/grasp_it_repo/blob/main/grasp_planning_vanilla_architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying Vanilla CNN, VGG-16, ResNet, InceptionNet(ViT if possible)\n",
        "1. Dataloader:(Used this [tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html))\n",
        "*   Add all four channels of image into 1 RGBD image.\n",
        "*   Get position and orientation from csv file and try to add it in one dataloader or figure out some other way.\n",
        "\n",
        "2. Currently predicting only position and orientation of the gripper:\n",
        "*  Loss function for orientation to be quaternions is custom made.\n",
        "*  Total loss= (loss1)X(0.5) + (loss2)X(0.5)"
      ],
      "metadata": {
        "id": "dwQjsF3USsDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CyM2W-N9R7F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecac3e31-a7fe-4bdb-a049-cbea4d914b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of val dataset loader:143\n",
            "torch.Size([16, 4, 512, 512])\n",
            "torch.Size([16, 5, 3])\n",
            "torch.Size([16, 5, 4])\n"
          ]
        }
      ],
      "source": [
        "#CustomDataLoader\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define custom dataset class\n",
        "class RGBDDataset(Dataset):\n",
        "    def __init__(self, rgb_dir, csv_file, depth_dir, transform=None):\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.depth_dir = depth_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get list of filenames in the directories\n",
        "        self.rgb_files = sorted(os.listdir(rgb_dir))\n",
        "        self.depth_files = sorted(os.listdir(depth_dir))\n",
        "\n",
        "        # Ensure the number of RGB and depth images are the same\n",
        "        assert len(self.rgb_files) == len(self.depth_files), \"Number of RGB and depth images do not match\"\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rgb_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load RGB and depth images\n",
        "        rgb_path = os.path.join(self.rgb_dir, self.rgb_files[idx])\n",
        "        depth_path = os.path.join(self.depth_dir, self.depth_files[idx])\n",
        "        rgb_img = Image.open(rgb_path).convert('RGB')\n",
        "        depth_img = Image.open(depth_path)\n",
        "        #Converting depth images to (0,1) range\n",
        "        depth_array = np.array(depth_img)\n",
        "        scaled_depth_array = (depth_array - depth_array.min()) / (depth_array.max() - depth_array.min()+1e-8)\n",
        "        depth_img = Image.fromarray(scaled_depth_array)\n",
        "\n",
        "\n",
        "        # Apply transformations if specified\n",
        "        if self.transform:\n",
        "            rgb_img = self.transform(rgb_img)\n",
        "            depth_img = self.transform(depth_img)\n",
        "\n",
        "        # Combine RGB and depth images into RGBD\n",
        "        rgbd_img = torch.cat((rgb_img, depth_img), dim=0)\n",
        "        # Get position and orientation values for all five sets\n",
        "        positions = []\n",
        "        orientations = []\n",
        "        for i in range(5):\n",
        "            idx_values = self.df.iloc[idx * 5 + i]\n",
        "            positions.append(torch.tensor(idx_values[['X', 'Y', 'Z']].values))\n",
        "            orientations.append(torch.tensor(idx_values[['x_q', 'y_q', 'z_q', 'w_q']].values))\n",
        "\n",
        "        positions = torch.stack(positions)  # Convert list of tensors to a single tensor\n",
        "        orientations = torch.stack(orientations)  # Convert list of tensors to a single tensor\n",
        "\n",
        "        return rgbd_img, positions, orientations\n",
        "\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # Resize to match input size of CNN architecture if required\n",
        "    #transforms.CenterCrop(512), #if we want to use the exact image without losing aspect ratio\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "])\n",
        "\n",
        "# Initialize dataset\n",
        "rgb_dir = '/content/drive/MyDrive/Masters_thesis/Dataset_1/dataset_1(depth=1,2)/rgb'\n",
        "depth_dir = '/content/drive/MyDrive/Masters_thesis/Dataset_1/dataset_1(depth=1,2)/depth'\n",
        "csv_file = '/content/drive/MyDrive/Masters_thesis/Dataset_1/merged_top_5_entries.csv'\n",
        "dataset = RGBDDataset(rgb_dir,csv_file, depth_dir, transform=transform)\n",
        "\n",
        "# Initialize DataLoader\n",
        "batch_size = 16\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f\"Length of val dataset loader:{len(dataloader)}\")\n",
        "a,b,c = (next(iter(dataloader)))\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Tq8H0ZyO5kMh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class YourClassName:  # Make sure to replace 'YourClassName' with the actual class name\n",
        "    def __init__(self):\n",
        "        self.df = pd.read_csv('/content/drive/MyDrive/Masters_thesis/Dataset_1/merged_top_5_entries.csv')\n",
        "\n",
        "    def your_method_name(self, idx):\n",
        "        positions = []\n",
        "        orientations = []\n",
        "        for i in range(5):\n",
        "            idx_values = self.df.iloc[idx * 5 + i]\n",
        "            positions.append(torch.tensor(idx_values[['X', 'Y', 'Z']].values))\n",
        "            orientations.append(torch.tensor(idx_values[['x_q', 'y_q', 'z_q', 'w_q']].values))\n",
        "        return positions, orientations\n",
        "\n",
        "# Usage:\n",
        "your_instance = YourClassName()\n",
        "idx = 2000  # Example value for idx\n",
        "positions, orientations = your_instance.your_method_name(idx)\n",
        "print(positions)\n",
        "print(orientations)\n"
      ],
      "metadata": {
        "id": "0V3VDtVEbEw2",
        "outputId": "868724c9-3910-497e-dc59-0ebeaa0da489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([-0.0057, -0.0916,  0.1387], dtype=torch.float64), tensor([-0.0105, -0.0661,  0.1243], dtype=torch.float64), tensor([-0.0631,  0.1167,  0.2778], dtype=torch.float64), tensor([-0.0239, -0.1040,  0.1898], dtype=torch.float64), tensor([-0.0046, -0.1293,  0.1048], dtype=torch.float64)]\n",
            "[tensor([-0.0492,  0.9567, -0.2395,  0.1582], dtype=torch.float64), tensor([ 0.0534,  0.1872, -0.0268,  0.9805], dtype=torch.float64), tensor([ 0.8014,  0.0837,  0.1378, -0.5760], dtype=torch.float64), tensor([ 3.2528e-02,  9.7336e-01, -2.2695e-01, -6.2641e-04],\n",
            "       dtype=torch.float64), tensor([-0.0118,  0.9868,  0.0361,  0.1577], dtype=torch.float64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization block to see if the images are correctly loaded"
      ],
      "metadata": {
        "id": "BFiIYUt7Sywn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract a batch of images from the dataloader\n",
        "images_batch,  = next(iter(dataloader))\n",
        "\n",
        "# Define the number of images to visualize\n",
        "num_images = 4\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(2, num_images, figsize=(15, 5))\n",
        "\n",
        "# Loop through the images in the batch\n",
        "for i in range(num_images):\n",
        "    # Extract the RGB and depth images from the batch\n",
        "    rgb_img = images_batch[i, :3]  # RGB channels\n",
        "    depth_img = images_batch[i, 3]  # Depth channel\n",
        "\n",
        "    # Convert tensors to numpy arrays\n",
        "    rgb_img_np = rgb_img.permute(1, 2, 0).cpu().numpy()  # Permute dimensions and convert to numpy array\n",
        "    depth_img_np = depth_img.cpu().numpy()\n",
        "    # Plot RGB image\n",
        "    axes[0,i].imshow(rgb_img_np)\n",
        "    axes[0,i].set_title('RGB Image')\n",
        "    axes[0,i].axis('off')\n",
        "\n",
        "    # Plot depth image\n",
        "    axes[1,i].imshow(depth_img_np, cmap='gray', alpha=1)  # Overlay depth image with transparency\n",
        "    axes[1,i].set_title('D Image')\n",
        "    axes[1,i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "R0cWO031_m7Q",
        "outputId": "714030d3-bcca-431d-e835-511ae85eea20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper functions:\n",
        "* Loss functions\n",
        "* Optimizer\n",
        "* Accuracy function\n",
        "* Maybe visualisation of results\n"
      ],
      "metadata": {
        "id": "EEEX4v_uv6Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper functions and Quaternion loss function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def quaternion_loss(q_actual, q_predicted):\n",
        "    \"\"\"\n",
        "    Compute quaternion loss between actual and predicted quaternions.\n",
        "\n",
        "    Args:\n",
        "        q_actual (torch.Tensor): Actual quaternions (batch_size x num_outputs x 4).\n",
        "        q_predicted (torch.Tensor): Predicted quaternions (batch_size x num_outputs x 4).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Quaternion loss.\n",
        "    \"\"\"\n",
        "    # Compute dot product\n",
        "    dot_product = torch.sum(q_actual * q_predicted, dim=2)\n",
        "\n",
        "    # Take absolute difference from 1\n",
        "    loss = 1 - torch.abs(dot_product)\n",
        "\n",
        "    return loss.mean()  # Return mean loss over the batch and number of outputs\n",
        "\n",
        "# Example usage:\n",
        "# Assuming positions and orientations are tensors of shape (batch_size, num_outputs, 3) and (batch_size, num_outputs, 4) respectively\n",
        "position_criterion = nn.MSELoss()  # Mean Squared Error for position\n",
        "\n",
        "# Calculate losses\n",
        "position_loss = position_criterion(positions, actual_positions)\n",
        "orientation_loss = quaternion_loss(orientations, actual_orientations)\n",
        "\n",
        "# Total loss\n",
        "total_loss = position_loss + orientation_loss\n",
        "\n",
        "# Backward pass and optimization\n",
        "optimizer.zero_grad()\n",
        "total_loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "id": "_GOFLHaSS0qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BXNgvuwgS2Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vanilla CNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_Position_Orientation(nn.Module):\n",
        "    def __init__(self, num_outputs=5):\n",
        "        super(CNN_Position_Orientation, self).__init__()\n",
        "        self.num_outputs = num_outputs\n",
        "\n",
        "        # Define convolutional layers for image processing\n",
        "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Define fully connected layers for position prediction\n",
        "        self.fc_position1 = nn.Linear(64 * 64 * 64, 512)\n",
        "        self.fc_position2 = nn.Linear(512, 3 * num_outputs)  # Output 5 sets of 3D positions\n",
        "\n",
        "        # Define fully connected layers for orientation prediction\n",
        "        #self.fc_orientation1 = nn.Linear(64 * 32 * 32, 512)\n",
        "        #self.fc_orientation2 = nn.Linear(512, 4 * num_outputs)  # Output 10 sets of quaternions\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through convolutional layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        # Flatten the output for fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Position prediction\n",
        "        position = F.relu(self.fc_position1(x))\n",
        "        position = self.fc_position2(position)\n",
        "        position = position.view(-1, self.num_outputs, 3)  # Reshape to (batch_size, num_outputs, 3)\n",
        "\n",
        "        # Orientation prediction\n",
        "        #orientation = F.relu(self.fc_orientation1(x))\n",
        "        #orientation = self.fc_orientation2(orientation)\n",
        "        #orientation = orientation.view(-1, self.num_outputs, 4)  # Reshape to (batch_size, num_outputs, 4)\n",
        "\n",
        "        return position\n",
        "import torch\n",
        "\n",
        "def accuracy(predictions, targets, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Calculate the accuracy based on Euclidean distance between predictions and targets.\n",
        "\n",
        "    Args:\n",
        "    - predictions (torch.Tensor): Predicted positions (batch_size, num_outputs, 3).\n",
        "    - targets (torch.Tensor): Actual positions (batch_size, num_outputs, 3).\n",
        "    - threshold (float): Maximum allowed Euclidean distance for a prediction to be considered accurate.\n",
        "\n",
        "    Returns:\n",
        "    - accuracy (float): Percentage of accurate predictions.\n",
        "    \"\"\"\n",
        "    batch_size, num_outputs, _ = predictions.size()\n",
        "    num_correct = 0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for j in range(num_outputs):\n",
        "            pred = predictions[i, j]\n",
        "            target = targets[i, j]\n",
        "            distance = torch.norm(pred - target)  # Calculate Euclidean distance\n",
        "            if distance <= threshold:\n",
        "                num_correct += 1\n",
        "\n",
        "    total_predictions = batch_size * num_outputs\n",
        "    accuracy = (num_correct / total_predictions) * 100.0\n",
        "\n",
        "    return accuracy\n",
        "def calculate_accuracy(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for rgbd_images, positions, orientations in dataloader:\n",
        "            positions = positions.float()\n",
        "            outputs = model(rgbd_images)\n",
        "            batch_accuracy = accuracy(outputs, positions)  # Use the previously defined accuracy function\n",
        "            total_accuracy += batch_accuracy\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "    return total_accuracy / len(dataloader.dataset)  # Return average accuracy\n",
        "\n",
        "# Example usage:\n",
        "# Instantiate the model\n",
        "model = CNN_Position_Orientation(num_outputs=5)\n",
        "\n",
        "# Assuming rgb_d_image is your input RGBD image tensor of shape (batch_size, channels, height, width)\n",
        "# Forward pass\n",
        "\n",
        "positions = model(a)\n",
        "print(positions.shape)\n",
        "# positions shape: (batch_size, num_outputs, 3)\n",
        "# orientations shape: (batch_size, num_outputs, 4)\n"
      ],
      "metadata": {
        "id": "pPKe-z1WSzKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952e2bb6-9f9c-411c-d0ee-31889ab2f98b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the training parameters\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNN_Position_Orientation(num_outputs=5)\n",
        "position_criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    for batch_idx, (rgbd_images, positions, orientations) in enumerate(dataloader):\n",
        "        # Forward pass\n",
        "        positions= positions.float()\n",
        "        outputs = model(rgbd_images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = position_criterion(outputs, positions)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print batch statistics\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 10 == 9:  # Print every 10 batches\n",
        "            print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, epochs, batch_idx+1, len(dataloader), total_loss / 10))\n",
        "            total_loss = 0.0\n",
        "        # Calculate accuracy after each epoch\n",
        "    epoch_accuracy = calculate_accuracy(model, dataloader)\n",
        "    print('Epoch [{}/{}], Accuracy: {:.2f}%'.format(epoch+1, epochs, epoch_accuracy))\n",
        "    total_accuracy += epoch_accuracy\n",
        "\n",
        "print('Training finished!')\n"
      ],
      "metadata": {
        "id": "oDuM47Eh6xDR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}